## 10大常见排序算法的介绍

| 排序算法      | 时间复杂度（最坏） | 时间复杂度（平均） | 空间复杂度 | 稳定性 |
|---------------|--------------------|--------------------|------------|--------|
| 冒泡排序      | \(O(n^2)\)         | \(O(n^2)\)         | \(O(1)\)   | 稳定   |
| 选择排序      | \(O(n^2)\)         | \(O(n^2)\)         | \(O(1)\)   | 不稳定 |
| 插入排序      | \(O(n^2)\)         | \(O(n^2)\)         | \(O(1)\)   | 稳定   |
| 快速排序      | \(O(n^2)\)         | \(O(n \log n)\)    | \(O(\log n)\) | 不稳定 |
| 归并排序      | \(O(n \log n)\)    | \(O(n \log n)\)    | \(O(n)\)   | 稳定   |
| 堆排序        | \(O(n \log n)\)    | \(O(n \log n)\)    | \(O(1)\)   | 不稳定 |
| 希尔排序      | \(O(n^2)\)         | \(O(n \log n)\)    | \(O(1)\)   | 不稳定 |
| 计数排序      | \(O(n + k)\)       | \(O(n + k)\)       | \(O(n + k)\) | 稳定   |
| 基数排序      | \(O(d \times (n + k))\) | \(O(d \times (n + k))\) | \(O(n + k)\) | 稳定   |
| 桶排序        | \(O(n^2)\)         | \(O(n + k)\)       | \(O(n + k)\) | 依赖桶内排序 |


## 排序算法的执行效率

对于排序算法的执行效率，我们一般通过以下几个方面来衡量

1. 最好情况、最坏情况、平均情况时间复杂度
2. 时间复杂度的系数、常数、低阶
3. 比较次数和交换次数

## 排序算法的内存消耗
<img src="./img/sort-1.png" width="500" height="auto">

我们前面讲过，算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。不过，针对排序算法的空间复杂度，我们还引入了一个新的概念，原地排序（Sorted in place）。原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。冒泡、插入、选择排序，都是原地排序算法。

## 排序算法的稳定性

稳定性。这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

---

# 冒泡排序

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作


插入排序的不稳定性解释

比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了

<img src="./img/sort-2.png" width="500" height="auto">


## 归并排序
<img src="./img/sort-3.png" width="500" height="auto">

### 归并排序的性能分析

#### 第一，归并排序是稳定的排序算法吗？

结合下图画的归并排序，你应该能发现，归并排序稳不稳定关键要看 merge() 函数，也就是两个有序子数组合并成一个有序数组的那部分代码。在合并的过程中，如果 A[p...q]和 A[q+1...r]之间有值相同的元素，那我们可以像伪代码中那样，先把 A[p...q]中的元素放入 tmp 数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。

<img src="./img/sort-4.png" width="500" height="auto">

#### 第二，归并排序的时间复杂度是多少？

归并排序涉及递归，时间复杂度的分析稍微有点复杂。我们正好借此机会来学习一下，如何分析递归代码的时间复杂度。在递归那一节我们讲过，递归的适用场景是，一个问题 a 可以分解为多个子问题 b、c，那求解问题 a 就可以分解为求解问题 b、c。问题 b、c 解决之后，我们再把 b、c 的结果合并成 a 的结果。如果我们定义求解问题 a 的时间是 T(a)，求解问题 b、c 的时间分别是 T(b) 和 T( c)，那我们就可以得到这样的递推关系式：
```text
T(a) = T(b) + T(c) + K
```
其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间。

从刚刚的分析，我们可以得到一个重要的结论：不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式。

我们假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。我们知道，merge() 函数合并两个有序子数组的时间复杂度是 O(n)。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：
```text
T(1) = C；   n=1时，只需要常量级的执行时间，所以表示为C。
T(n) = 2*T(n/2) + n； n>1
```
通过这个公式，如何来求解 T(n) 呢？还不够直观？那我们再进一步分解一下计算过程。

```text
T(n) = 2*T(n/2) + n
     = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
     = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
     = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
     ......
     = 2^k * T(n/2^k) + k * n
     ......
```

通过这样一步一步分解推导，我们可以得到 T(n) = 2^kT(n/2^k)+kn。当 T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到 k=log2n 。我们将 k 值代入上面的公式，得到 T(n)=Cn+nlog2n 。如果我们用大 O 标记法来表示的话，T(n) 就等于 O(nlogn)。所以归并排序的时间复杂度是 O(nlogn)。

从我们的原理分析和伪代码可以看出，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。

#### 归并排序的空间复杂度

实际上，递归代码的空间复杂度并不能像时间复杂度那样累加，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。

```go
// merge 使用哨兵值优化
func merge(left []int, right []int) []int {
	// 在 left 和 right 的末尾添加一个正无穷大值
	left = append(left, math.MaxInt64)
	right = append(right, math.MaxInt64)

	result := make([]int, 0, len(left)+len(right)-2) // 初始化结果切片
	i, j := 0, 0                                     // 指向 left 和 right 的索引

	for k := 0; k < len(left)+len(right)-2; k++ { // 总元素数 = 原数组长度的和
		if left[i] <= right[j] {
			result = append(result, left[i])
			i++
		} else {
			result = append(result, right[j])
			j++
		}
	}

	return result
}
```

**归并排序与快速排序的实现对比**

<img src="./img/sort-5.png" width="500" height="auto">

可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。


#### 思考题

现在你有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并吗？

#### 解决思路
**使用多路归并算法：**

每个日志文件内部已经是按时间戳从小到大排序好的。
使用一个最小堆（或优先队列）来合并这 10 个有序的日志文件。
关键点：

文件分块处理：由于单个文件较大，但内存有限，我们可以分块读取每个文件的一部分到内存中。
堆维护最小值：每次从堆中取出最小的时间戳所在的日志，并将其写入最终合并文件，然后从对应文件中再读取下一条日志，继续维持堆。


---
# 非比较排序

## 桶排序

<img src="./img/sort-6.png" width="500" height="auto">

### 时间复杂度分析

如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

**桶排序是否能够替换其他排序算法**

答案是否定的，因为桶排序的平均时间复杂度的条件比较苛刻，需要满足以下场景

1. 首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。
2. 其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。

### 适用场景

桶排序比较适合用在**外部排序**中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

## 计数排序

计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间

计数排序算法示意图

---

### **计数排序的整体步骤**
1. **初始化计数数组 \( C \)**
    - 定义一个大小为 \( k \) 的计数数组 \( C \)，其中 \( k \) 是输入数据的范围（假设数据值从 0 到 \( k-1 \)）。
    - 遍历数组 \( A \)，统计每个数出现的次数，存入 \( C \)。

2. **累加计数数组 \( C \)**
    - 将 \( C \) 中的每个值累加，以便 \( C[i] \) 表示数组中小于等于 \( i \) 的元素个数。

3. **构建结果数组 \( R \)**
    - 从右向左遍历输入数组 \( A \)，根据 \( C \) 的值确定当前数的位置，并将其放入结果数组 \( R \) 的正确位置。
    - 每次放置后，更新 \( C \) 的值（即对应位置减 1）。

4. **输出结果数组 \( R \)**
    - \( R \) 即为排序后的数组。

---

<img src="./img/sort-8.png" width="500" height="auto">

**适用场景**

1. 计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。
2. 计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数

## 基数排序

基数排序算法示意图

<img src="./img/sort-7.png" width="500" height="auto">

**适用场景**

基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了

## 如何设计一个通用、高性能的排序函数

### 如何快速优化快速排序

我们先来看下，为什么最坏情况下快速排序的时间复杂度是 O(n2) 呢？我们前面讲过，如果数据原来就是有序的或者接近有序的，每次分区点都选择最后一个数据，那快速排序算法就会变得非常糟糕，时间复杂度就会退化为 O(n2)。实际上，这种 O(n2) 时间复杂度出现的主要原因还是因为我们分区点选得不够合理。

这里介绍两个比较常用，比较简单的分区算法

#### 1. 三数取中法

我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”

#### 2. 随机法

随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选得很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。



